---
lang: en
title: "Perception"
description: "We develop technologies that accurately recognize users and surrounding situations based on information entered through various sensors and make comprehensive judgments accordingly."
date: 2019-10-03
weight: 3
header_transparent: true
fa_icon: false
icon: "assets/images/icons/icons8-color-palette-100.png"
thumbnail: "/assets/images/gen/research/perception-2.jpg"
image: "/assets/images/gen/research/perception-2.jpg"

hero:
  enabled: true
  heading: "Perception"
  sub_heading: "We develop technologies that accurately recognize users and surrounding situations based on information entered through various sensors and make comprehensive judgments accordingly."
  text_color: "#ffffff"
  background_color: ""
  background_gradient: true
  background_image_blend_mode: "overlay" # "overlay", "multiply", "screen"
  background_image: "/assets/images/gen/research/perception-2.jpg"
  fullscreen_mobile: false
  fullscreen_desktop: false
  height: 660px
  buttons:
    enabled: false
    list:
      - text: "Buy Now"
        url: "https://www.zerostatic.io/theme/jekyll-advance/"
        external: true
        fa_icon: false
        size: large
        outline: false
        style: "primary"
---

## Recognizing and executing commands based on users' faces, voices, gestures, and actions.
  - Deep learning model for emotion recognition through facial expressions.
  
  - Deep learning model for gesture and pose recognition.
  
  - Deep learning model for emotion recognition through voice.

## Accurate situation recognition and complex thinking through the fusion of various sensors.
  - Developing accurate feature extraction techniques and feature space projection for vision and voice inputs.
  
  - Enhancing accuracy through explicit/implicit alignment and joint learning.
  
## Personality formation through interaction with users.
  - Collecting and securing user data for interaction.
  - Personality formation of R.pet through continuous learning on Cloud and devices.

## Autonomous movement through simultaneous location estimation and map creation.
  - Stable map creation based on accurate current robot location estimation.
  
  - Efficiently processing various sensor data for rapid map construction.
  
  - Minimizing noise and errors through the fusion of various sensors like RGB, Lidar, etc.